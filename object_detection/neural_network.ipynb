{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Example\n",
    "\n",
    "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow.\n",
    "\n",
    "This example is using some of TensorFlow higher-level wrappers (tf.estimators, tf.layers, tf.metrics, ...), you can check 'neural_network_raw' example for a raw, and more detailed TensorFlow implementation.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.coco import COCODataset\n",
    "import utils.benchmark as bench_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# post-processing helper functions\n",
    "\n",
    "\n",
    "def initialize_colors():\n",
    "    colors_per_cat = list()\n",
    "    np.random.seed(13)  # 13\n",
    "    for _ in range(92):\n",
    "        B = np.random.randint(0, 256)\n",
    "        G = np.random.randint(0, 256)\n",
    "        R = np.random.randint(0, 256)\n",
    "        colors_per_cat.append((B, G, R))\n",
    "    return colors_per_cat\n",
    "\n",
    "\n",
    "COLORS_PER_CAT = initialize_colors()\n",
    "\n",
    "\n",
    "def draw_line(image, cat, x_0, y_0, x_1, y_1):\n",
    "    image = cv2.line(image,\n",
    "                     (x_0, y_0),\n",
    "                     (x_1, y_1),\n",
    "                     color=COLORS_PER_CAT[cat],\n",
    "                     lineType=cv2.LINE_AA,\n",
    "                     thickness=2)\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bbox(image, bbox, cat):\n",
    "    image = draw_line(image, cat, bbox[0], bbox[1], bbox[2], bbox[1])\n",
    "    image = draw_line(image, cat, bbox[0], bbox[1], bbox[0], bbox[3])\n",
    "    image = draw_line(image, cat, bbox[0], bbox[3], bbox[2], bbox[3])\n",
    "    image = draw_line(image, cat, bbox[2], bbox[3], bbox[2], bbox[1])\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FP16 SSD Inception v2 model preset\n",
    "\n",
    "input_shape = (300, 300)\n",
    "batch_size = 1\n",
    "threshold = 0.3\n",
    "path_to_model = \"ssd_inception_v2/ssd_inception_v2_tf_fp16.pb\"\n",
    "output_names = [\"detection_classes:0\", \"detection_boxes:0\", \"detection_scores:0\", \"num_detections:0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first let's load the model\n",
    "\n",
    "graph = tf.compat.v1.Graph()\n",
    "with graph.as_default():\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v1.gfile.GFile(path_to_model, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        graph_def.ParseFromString(serialized_graph)\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# please set DLS_NUM_THREADS prior to running this script\n",
    "\n",
    "# creating TF config\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.intra_op_parallelism_threads = bench_utils.get_intra_op_parallelism_threads()\n",
    "config.inter_op_parallelism_threads = 1\n",
    "\n",
    "# initialization of TF session\n",
    "sess = tf.compat.v1.Session(\n",
    "    config=config,\n",
    "    graph=graph\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preparing input and output dictionaries\n",
    "\n",
    "# creation of output dictionary\n",
    "output_dict = {output_name: graph.get_tensor_by_name(output_name) for output_name in output_names}\n",
    "\n",
    "# initialization of COCO dataset\n",
    "coco = COCODataset(\n",
    "    batch_size=batch_size,\n",
    "    color_model=\"BGR\",\n",
    "    images_filename_base=\"COCO_val2014_000000000000\"\n",
    ")\n",
    "\n",
    "# assignment of input image to input tensor\n",
    "feed_dict = {graph.get_tensor_by_name(\"image_tensor:0\"): coco.get_input_array(target_shape=input_shape)}\n",
    "\n",
    "# for the purpose of visualizing results let's load the image without pre-processing\n",
    "img = cv2.imread(str(coco.path_to_latest_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running the model\n",
    "\n",
    "# warm-up run\n",
    "_ = sess.run(output_dict, feed_dict)\n",
    "\n",
    "# actual run\n",
    "start = time.time()\n",
    "output = sess.run(output_dict, feed_dict)\n",
    "finish = time.time()\n",
    "\n",
    "latency_ms = (finish - start) * 1000\n",
    "print(\"SSD Inception v2 FP16 latency: {:.0f} ms\".format(latency_ms))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualizing output\n",
    "\n",
    "# post-processing\n",
    "for i in range(batch_size):\n",
    "    for d in range(int(output[\"num_detections:0\"][i])):\n",
    "\n",
    "        # the detected object does not exceed a set threshold we skip it\n",
    "        if output[\"detection_scores:0\"][i][d] < threshold:\n",
    "            continue\n",
    "\n",
    "        # first let's switch order of bbox boundaries from [top left bottom right] to [left top right bottom]\n",
    "        converted_bbox = coco.convert_bbox_to_coco_order(output[\"detection_boxes:0\"][i][d] * shape[0], absolute=False)\n",
    "\n",
    "        # then rescale back to original image ratio\n",
    "        converted_bbox = coco.rescale_bbox(i, converted_bbox)\n",
    "\n",
    "        # we can now draw bbox on the original input image\n",
    "        img = draw_bbox(img, converted_bbox, int(output[\"detection_classes:0\"][i][d]))\n",
    "\n",
    "# show the post-processed image\n",
    "cv2.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# conclusion\n",
    "sess.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}