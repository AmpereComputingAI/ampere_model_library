{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Examples\n",
    "\n",
    "## COCO Dataset Overview\n",
    "<img src=\"https://cocodataset.org/images/coco-logo.png\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "These examples are using subset of COCO object detection validation set from year 2014.\n",
    "COCO is a large-scale object detection, segmentation, and captioning dataset.\n",
    "\n",
    "More info can be found here: https://cocodataset.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.coco import COCODataset\n",
    "import utils.benchmark as bench_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# post-processing helper functions\n",
    "\n",
    "\n",
    "def initialize_colors():\n",
    "    colors_per_cat = list()\n",
    "    np.random.seed(13)  # 13\n",
    "    for _ in range(92):\n",
    "        B = np.random.randint(0, 256)\n",
    "        G = np.random.randint(0, 256)\n",
    "        R = np.random.randint(0, 256)\n",
    "        colors_per_cat.append((B, G, R))\n",
    "    return colors_per_cat\n",
    "\n",
    "\n",
    "COLORS_PER_CAT = initialize_colors()\n",
    "\n",
    "\n",
    "def draw_line(image, cat, x_0, y_0, x_1, y_1):\n",
    "    image = cv2.line(image,\n",
    "                     (x_0, y_0),\n",
    "                     (x_1, y_1),\n",
    "                     color=COLORS_PER_CAT[cat],\n",
    "                     lineType=cv2.LINE_AA,\n",
    "                     thickness=2)\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bbox(image, bbox, cat):\n",
    "    bbox = [int(elem) for elem in bbox]\n",
    "    image = draw_line(image, cat, bbox[0], bbox[1], bbox[2], bbox[1])\n",
    "    image = draw_line(image, cat, bbox[0], bbox[1], bbox[0], bbox[3])\n",
    "    image = draw_line(image, cat, bbox[0], bbox[3], bbox[2], bbox[3])\n",
    "    image = draw_line(image, cat, bbox[2], bbox[3], bbox[2], bbox[1])\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SSD Inception v2 in fp16 precision\n",
    "\n",
    "This example shows the performance of SSD Inception v2 model converted to fp16 precision.\n",
    "Models in fp16 precision are expected to offer accuracy on par with fp32 counterparts and up to 2x inference speed-up \n",
    "on compatible hardware when run with DLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = (300, 300)\n",
    "batch_size = 1\n",
    "threshold = 0.3\n",
    "path_to_model = \"ssd_inception_v2/ssd_inception_v2_tf_fp16.pb\"\n",
    "output_names = [\"detection_classes:0\", \"detection_boxes:0\", \"detection_scores:0\", \"num_detections:0\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first let's load the model\n",
    "\n",
    "graph = tf.compat.v1.Graph()\n",
    "with graph.as_default():\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v1.gfile.GFile(path_to_model, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        graph_def.ParseFromString(serialized_graph)\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! DLS_NUM_THREADS should be set prior to launching jupyter notebook !\n",
    "\n",
    "# creating TF config\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.intra_op_parallelism_threads = bench_utils.get_intra_op_parallelism_threads()\n",
    "config.inter_op_parallelism_threads = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preparing input and output dictionaries\n",
    "\n",
    "# creation of output dictionary\n",
    "output_dict = {output_name: graph.get_tensor_by_name(output_name) for output_name in output_names}\n",
    "\n",
    "# initialization of COCO dataset\n",
    "coco = COCODataset(\n",
    "    batch_size=batch_size,\n",
    "    color_model=\"BGR\",\n",
    "    images_filename_base=\"COCO_val2014_000000000000\"\n",
    ")\n",
    "\n",
    "# assignment of input image to input tensor\n",
    "feed_dict = {graph.get_tensor_by_name(\"image_tensor:0\"): coco.get_input_array(target_shape=input_shape)}\n",
    "\n",
    "# for the purpose of visualizing results let's load the image without pre-processing\n",
    "img = cv2.imread(str(coco.path_to_latest_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running the model with DLS enabled\n",
    "\n",
    "tf.DLS.force_enable()\n",
    "\n",
    "with tf.compat.v1.Session(config=config, graph=graph) as sess:\n",
    "    # warm-up run\n",
    "    _ = sess.run(output_dict, feed_dict)\n",
    "\n",
    "    # actual run\n",
    "    start = time.time()\n",
    "    output_dls = sess.run(output_dict, feed_dict)\n",
    "    finish = time.time()\n",
    "\n",
    "latency_ms = (finish - start) * 1000\n",
    "print(\"\\nSSD Inception v2 FP16 latency with DLS: {:.0f} ms\\n\".format(latency_ms))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running the model with DLS disabled\n",
    "\n",
    "tf.DLS.force_disable()\n",
    "\n",
    "with tf.compat.v1.Session(config=config, graph=graph) as sess:\n",
    "    # warm-up run\n",
    "    _ = sess.run(output_dict, feed_dict)\n",
    "\n",
    "    # actual run\n",
    "    start = time.time()\n",
    "    output_no_dls = sess.run(output_dict, feed_dict)\n",
    "    finish = time.time()\n",
    "\n",
    "latency_ms = (finish - start) * 1000\n",
    "print(\"\\nSSD Inception v2 FP16 latency without DLS: {:.0f} ms\\n\".format(latency_ms))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualizing output\n",
    "\n",
    "# post-processing\n",
    "def post_process(image, output):\n",
    "    for i in range(batch_size):\n",
    "        for d in range(int(output[\"num_detections:0\"][i])):\n",
    "\n",
    "            # the detected object does not exceed a set threshold we skip it\n",
    "            if output[\"detection_scores:0\"][i][d] < threshold:\n",
    "                continue\n",
    "\n",
    "            # first let's switch order of bbox boundaries from [top left bottom right] to [left top right bottom]\n",
    "            converted_bbox = coco.convert_bbox_to_coco_order(\n",
    "                output[\"detection_boxes:0\"][i][d] * input_shape[0],\n",
    "                1, 0, 3, 2,\n",
    "                absolute=False\n",
    "            )\n",
    "\n",
    "            # then rescale back to original image ratio\n",
    "            converted_bbox = coco.rescale_bbox(i, converted_bbox)\n",
    "\n",
    "            # we can now draw bbox on the original input image\n",
    "            image = draw_bbox(image, converted_bbox, int(output[\"detection_classes:0\"][i][d]))\n",
    "\n",
    "    return image\n",
    "\n",
    "# show the post-processed images\n",
    "plt.imshow(cv2.cvtColor(post_process(img, output_dls), cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print(\"Output with DLS enabled\\n\")\n",
    "\n",
    "plt.imshow(cv2.cvtColor(post_process(img, output_no_dls), cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print(\"Output with DLS disabled\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}